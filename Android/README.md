

===============================
Data.caida.org
===============================
datasets/topology/

--------------------
ksitter-as-links
--------------------
tools/asadj2graph.pl
  	Desc: filter AS adjacency files into AS graph adjacency matrices
	Input: AS adjacency files: http://www.caida.org/tools/measurement/skitter/as_adjacencies.xml
	Output: AS graph adjacency matrices in the following format: "line AS_X AS_Y" - represents a link between AS_X and AS_Y

* skitter is a tool for actively probing the Internet in order to analyze topology and performance; only used until 2008.
* Archipelago (Ark) is the replacement tool for collecting similar data, and produces the IPv4 Routed /24 Topology Dataset

--------------------
ipv4.allpref24-aslinks
--------------------
* Data files for "recent" data in the project are in the format "cycle-aslinks.l7.t1.cXXXXXX.YYYYMMDD.txt.gz" 
	ie. "cycle-aslinks.l7.t1.c000359.20090103.txt.gz"



===============================
aspipeline
===============================
aspipeline.py
 	* Takes files in data folder, runs all the maths on them, and creates a file in the out folder named with the date
 	* Uses eigenvector.py

historicalstats.py
	* Cannot find where this file is being used
	* Uses asgraph.py

asyearsfiltered
	* Cannot find where this is being used

--------------------
data
--------------------
* Pulled a single representative file out of the skitter and ipv4 folders (Data.caida.org)
* Did not always pick Jan 1, not sure why, perhaps picked dates that corresponded with timeline events?

--------------------
out
--------------------
* Results of aspipeline.py




===============================
geopipeline
===============================
geopipeline.py
	* Uses data/GeoIPASNum2.csv
	* Uses data/GeoLiteCity_20130101/GeoLiteCity-Blocks.csv
	* Uses data/GeoLiteCity_20130101/GeoLiteCity-Location.csv
	* Writes out to "../loc.py"

--------------------
data
--------------------
* Taken from http://dev.maxmind.com/geoip/legacy/geolite/
* May need data attribution:
	This product includes GeoLite data created by MaxMind, available from 
	<a href="http://www.maxmind.com">http://www.maxmind.com</a>.

--------------------
out
--------------------
* Contains loc.py, but since geopipeline does not appear to write to this folder, this file may not be the most recent result




===============================
companynames
===============================
* Includes GeoIPAsNum2.csv (Also from http://dev.maxmind.com/geoip/legacy/geolite/)

companynames.py
	* Uses asinfo.json as input data (asinfo)
	* Uses data.txt as input data (vals)
	* Creates top100.csv

asinfo.js
	* ??? No idea where this file comes from	

data.txt
	* ??? No idea where this file comes from
	* Appears to be used to generate top100.csv

top100.csv
	* Generated by companynames.py?
	* List of ASNum,ASName for "top" ASCompanies? 


===============================
asgraph
===============================
* Looks like it contains ALL the data from the Ark (ipv4.allpref24-aslinks) data collection method
* Could be the superset of the data used in aspipeline/data (from 2008 onwards)
* Also, asgraph/cycle-aslinks.l7.t1.c002162.20120916.txt used in getasinfo.py to grab all ASNs 
	* Why this file? Because it was the most "up to date" at the time?


===============================
ashhtml
===============================
* Looks like scraped HTML data for each AS
* Each file contains ASBlock numbers, names and addresses (and lots of other infoz)
* All files generated by getasinfo2.py
* Could be used for archiving purposes - I do not see these HTML pages being used anywhere


===============================
Top Level Scripts / files
===============================

getasinfo.py
	* Pulls data from asgraph/cycle-aslinks.l7.t1.c002162.20120916.txt to get the full list of ASNs to query
	* Calls http://ipduh.com/ip/whois/as/?<ASNNUm> to get the HTML code that contains a bunch of info for each ASN.
	* Scrapes the HTML for specific fields, and creates an "asinfo" json object that is written directly into results.py

getasinfo2.py
	* Same as getasinfo.py except...
	* Instead of picking out fields and writing to results.py, it generates the HTML pages found in the ashtml folder
	* Does not pick out specific fields or write to results.py

results.py
	* Generated by getasinfo.py

loc.py
	* Generated by geopipeline/geopipeline.py

converttojson.py
	* Does not appear to be used

as2attr.txt
	* Does not appear to be used 

as_rel.txt
	* Does not appear to be used 

asinfo.json / asinfo2.json
	* Does not appear to be used
	* Perhaps a relic from before asinfo was being written into results.py?


===============================
App Data
===============================

--------------------
data
--------------------
* Single txt files for each year
* Files pulled directly from aspipeline/out



Android app is using:
/data/
* history.json


MapController.cpp
* Hardcodes in lastTimelinePoint
* Uses unified.txt to load in data



Files to update when adding a new year:

data folder

history.json: 


